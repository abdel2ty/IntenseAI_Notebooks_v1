{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdel2ty/IntenseAI_Notebooks_v1/blob/main/numpy_assignments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ie7lnVo77Twa"
      },
      "source": [
        "\n",
        "<a href=\"https://www.zero-grad.com/\">\n",
        "         <img alt=\"Zero Grad\" src=\"https://i.postimg.cc/y8LZ0CM6/linear-Algebra.png\" >\n",
        "      </a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKhL2cN3W_Uu"
      },
      "source": [
        "# üß™ Assignment 1: Build Your Own `train_test_split_np()` Using NumPy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIyagsdyW_Uw"
      },
      "source": [
        "##  Introduction:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mSXlvy_W_Ux"
      },
      "source": [
        "\n",
        "\n",
        "In Machine Learning, we build models that **learn from data** and then **make predictions** on new, unseen data.\n",
        "\n",
        "But if we train and test our model on the same data, we won't know if it's actually good ‚Äî it might just be memorizing the data (overfitting). To avoid this, we **split the dataset** into two parts:\n",
        "\n",
        "- **Training Set** üß†  \n",
        "  Used by the model to learn patterns from data.\n",
        "\n",
        "- **Testing Set** üß™  \n",
        "  Used to evaluate how well the model performs on new, unseen data.\n",
        "\n",
        "This approach helps us **estimate how the model will perform in the real world**.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚öñÔ∏è Common Split Ratios\n",
        "\n",
        "- **80% Train / 20% Test** ‚Äì most common for general tasks.\n",
        "- **70% Train / 30% Test** ‚Äì when you want more test data.\n",
        "- **90% Train / 10% Test** ‚Äì if your dataset is large.\n",
        "\n",
        "There's no one \"right\" ratio ‚Äî it depends on your dataset size and use case.\n",
        "\n",
        "---\n",
        "\n",
        "### üîÄ Should We Shuffle the Data?\n",
        "\n",
        "Yes!  \n",
        "If your data is ordered (e.g. time-based), you should **shuffle** it before splitting to avoid bias.\n",
        "\n",
        "Shuffling ensures that both the training and test sets represent the overall data distribution fairly.\n",
        "\n",
        "---\n",
        "\n",
        "### üß† Real-Life Analogy\n",
        "\n",
        "Imagine you're studying for an exam.\n",
        "\n",
        "- You **practice with sample questions** (training set).\n",
        "- Then you **test yourself with new questions** you've never seen (test set).\n",
        "\n",
        "If you only \"test\" yourself using the same practice questions, you're not really testing your understanding ‚Äî you're just repeating.\n",
        "\n",
        "---\n",
        "\n",
        "### üß™ Summary\n",
        "\n",
        "| Term           | Purpose                          |\n",
        "|----------------|----------------------------------|\n",
        "| Training Set   | Learn from it                    |\n",
        "| Testing Set    | Evaluate model on unseen data    |\n",
        "| Shuffle        | Avoid bias from data order       |\n",
        "| Test Ratio     | Controls how much data is held out for testing |\n",
        "\n",
        "Understanding this concept is the first step toward building reliable, real-world ML models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bv6GG29MW_Uz"
      },
      "source": [
        "## Implementation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXWNCQEhW_Uz"
      },
      "source": [
        "\n",
        "\n",
        "Create a custom `train_test_split_np()` function using **NumPy only**, similar to scikit-learn's `train_test_split`, with full control over:\n",
        "\n",
        "- Test ratio (e.g., 20% test)\n",
        "- Shuffle behavior\n",
        "- Random seed for reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4S55z0e6W_U0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def train_test_split_np(X, y, test_ratio=0.2, seed=None, shuffle=True):\n",
        "    \"\"\"\n",
        "    Splits X and y into training and testing sets using NumPy only.\n",
        "\n",
        "    Parameters:\n",
        "        X (ndarray): Feature array of shape (n_samples, n_features)\n",
        "        y (ndarray): Target array of shape (n_samples, 1) or (n_samples,)\n",
        "        test_ratio (float): Ratio of data to use for testing (0 < test_ratio < 1)\n",
        "        seed (int): Optional random seed for reproducibility\n",
        "        shuffle (bool): Whether to shuffle data before splitting\n",
        "\n",
        "    Returns:\n",
        "        X_train, X_test, y_train, y_test\n",
        "    \"\"\"\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    n_samples = X.shape[0]\n",
        "    indices = np.arange(n_samples)\n",
        "\n",
        "    if shuffle:\n",
        "        indices = np.random.permutation(n_samples)\n",
        "\n",
        "    test_size = int(n_samples * test_ratio)\n",
        "    test_indices = indices[:test_size]\n",
        "    train_indices = indices[test_size:]\n",
        "\n",
        "    X_train = X[train_indices]\n",
        "    X_test = X[test_indices]\n",
        "    y_train = y[train_indices]\n",
        "    y_test = y[test_indices]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01YqqNxkW_U2",
        "outputId": "b1fc9082-97a4-4ee3-f45e-5c7327b021ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original X:\n",
            " [[ 1  2]\n",
            " [ 3  4]\n",
            " [ 5  6]\n",
            " [ 7  8]\n",
            " [ 9 10]]\n",
            "Original y:\n",
            " [1 2 3 4 5]\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]])\n",
        "y = np.array([1, 2, 3, 4, 5])\n",
        "\n",
        "print(\"Original X:\\n\", X)\n",
        "print(\"Original y:\\n\", y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcwX7qppW_U3",
        "outputId": "2cf3c3a3-b8d6-4f14-8e56-cfb0e5c73acf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train:\n",
            " [[ 9 10]\n",
            " [ 5  6]\n",
            " [ 1  2]\n",
            " [ 7  8]]\n",
            "X_test:\n",
            " [[3 4]]\n",
            "y_train:\n",
            " [5 3 1 4]\n",
            "y_test:\n",
            " [2]\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split_np(X, y, test_ratio=0.2, seed=42, shuffle=True)\n",
        "\n",
        "print(\"X_train:\\n\", X_train)\n",
        "print(\"X_test:\\n\", X_test)\n",
        "print(\"y_train:\\n\", y_train)\n",
        "print(\"y_test:\\n\", y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXQoZ2aPW_U4"
      },
      "source": [
        "# üìà Assignment 2: Build Linear Regression from Scratch (Using Your Train-Test Split)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3J6xE2VW_U5"
      },
      "source": [
        "## üß† What You'll Learn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zA5Av7PYW_U6"
      },
      "source": [
        "\n",
        "In this assignment, you‚Äôll build a **Linear Regression model** step-by-step using only **NumPy** ‚Äî and apply it to the training and test sets you created in **Assignment 1**.\n",
        "\n",
        "You will:\n",
        "\n",
        "- Use your own `train_test_split_np()` function  \n",
        "- Fit a line to training data using the **Normal Equation**  \n",
        "- Make predictions on test data\n",
        "\n",
        "\n",
        "\n",
        " üß™ **The Idea**\n",
        "\n",
        "Linear Regression tries to find the best-fitting line:\n",
        "\n",
        "```\n",
        "y = Œ∏‚ÇÄ + Œ∏‚ÇÅx\n",
        "```\n",
        "\n",
        "We use a mathematical formula (Normal Equation) to find the best values for `Œ∏‚ÇÄ` and `Œ∏‚ÇÅ`:\n",
        "\n",
        "```\n",
        "Œ∏ = (X·µÄX)‚Åª¬π X·µÄy\n",
        "```\n",
        "\n",
        "Then we use this line to make predictions for new data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aB7lS2HW_U6"
      },
      "source": [
        "## üìù Tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7R6KMt2dW_U7"
      },
      "source": [
        "### ‚úÖ Step 1: Generate the Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itnu0WLWW_U7",
        "outputId": "b4a9c15b-30c0-45fa-b491-397e99b99fc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape: (100, 1)\n",
            "y shape: (100, 1)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(42)\n",
        "X = 2 * np.random.rand(100, 1)\n",
        "y = 4 + 3 * X + np.random.randn(100, 1)\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBq6McJqW_U8"
      },
      "source": [
        "### ‚úÖ Step 2: Add Intercept Column (x‚ÇÄ = 1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BU9LpN72W_U8"
      },
      "source": [
        "> Example:\n",
        "\n",
        "![Adding 1](https://i.ibb.co/d0zpGpcB/adding-1.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOZ3fbfiW_U8",
        "outputId": "1fb2e003-a032-414e-eb20-d05cc663e120"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_b shape: (100, 2)\n"
          ]
        }
      ],
      "source": [
        "ones = np.ones((X.shape[0], 1))\n",
        "X_b = np.c_[ones, X]  # Add bias term\n",
        "\n",
        "print(\"X_b shape:\", X_b.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pf-g2XfsW_U9"
      },
      "source": [
        "### ‚úÖ Step 3: Split the Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykXlOiRtW_U9"
      },
      "source": [
        "Use your function to split `X` and `y`:\n",
        "\n",
        "```python\n",
        "X_train, X_test, y_train, y_test = train_test_split_np(X, y, test_ratio=0.2, seed=42)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SI2tN6k8W_U-",
        "outputId": "c8c5cbbd-e9a1-4f62-92b5-7ef97bf46adc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " X_train Shape: (80, 2)\n",
            " X_test Shape: (20, 2)\n",
            " y_train Shape: (80, 1)\n",
            " y_test Shape: (20, 1)\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split_np(X_b, y, test_ratio=0.2, seed=42, shuffle=True)\n",
        "\n",
        "print(\" X_train Shape:\", X_train.shape)\n",
        "print(\" X_test Shape:\", X_test.shape)\n",
        "print(\" y_train Shape:\", y_train.shape)\n",
        "print(\" y_test Shape:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-jCZFdEW_U-"
      },
      "source": [
        "### ‚úÖ Step 4: Compute Œ∏ Using the Normal Equation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZSaB4AuW_U-"
      },
      "source": [
        "![image.png](https://miro.medium.com/v2/resize:fit:1120/1*7ZiWm6xAF4oWiYfWklUMEw.jpeg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFCFqLkXW_U-",
        "outputId": "7c4d7a10-ef99-4c47-cc14-1595415412f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "theta_best shape: (2, 1)\n",
            "theta_best:\n",
            " [[4.21509616]\n",
            " [2.77011339]]\n"
          ]
        }
      ],
      "source": [
        "theta_best = np.linalg.inv(X_b.T @ X_b) @ X_b.T @ y\n",
        "\n",
        "print(\"theta_best shape:\", theta_best.shape)\n",
        "print(\"theta_best:\\n\", theta_best)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfbIl2i_W_U_"
      },
      "source": [
        "### ‚úÖ Step 5: Predict on the Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcvfZeQuW_U_",
        "outputId": "74a1605b-d24d-4fa7-bd4f-6969baa87a8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y_pred shape: (20, 1)\n",
            "y_pred:\n",
            " [[4.56722383]\n",
            " [9.1726426 ]\n",
            " [8.4935073 ]\n",
            " [7.88561985]\n",
            " [5.64879594]\n",
            " [6.65364079]\n",
            " [5.83364376]\n",
            " [8.99688487]\n",
            " [4.32913892]\n",
            " [6.29013335]\n",
            " [6.60816951]\n",
            " [7.58103241]\n",
            " [8.7329374 ]\n",
            " [9.47213722]\n",
            " [4.8776754 ]\n",
            " [5.07947481]\n",
            " [8.48810878]\n",
            " [4.62532032]\n",
            " [8.82701716]\n",
            " [5.15983847]]\n"
          ]
        }
      ],
      "source": [
        "y_pred = X_test @ theta_best\n",
        "\n",
        "print(\"y_pred shape:\", y_pred.shape)\n",
        "print(\"y_pred:\\n\", y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTN8Sb87W_U_"
      },
      "source": [
        "### ‚úÖ Step 6: Evaluate the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ok5aA7g4W_U_"
      },
      "source": [
        "Use **Mean Squared Error (MSE)** to evaluate your model's performance:\n",
        "\n",
        "<img src=\"https://www.i2tutorials.com/wp-content/media/2019/11/Differences-between-MSE-and-RMSE-1-i2tutorials.jpg\" width=\"400\">\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIopHziQW_VA",
        "outputId": "7bbd9884-0b80-416a-dc75-341d608c9831"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error (MSE): 0.6330083230690094\n"
          ]
        }
      ],
      "source": [
        "mse = np.mean((y_test - y_pred) ** 2)\n",
        "print(\"Mean Squared Error (MSE):\", mse)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "XYNa1JWM3JYN",
        "anhiG4MjIwTc",
        "XU6Bn5xu4P9O",
        "J36j55q4JDAG",
        "yToXMbvf_HcM",
        "F2C54w29JEzm",
        "rZQBujOJ-HsZ",
        "wbE6VrFHJF8W",
        "0_QN57WJF_HQ",
        "iNC-IUdPGDJe",
        "jqZekQSDJHKm",
        "oYHpwHEPGgvg",
        "b83I19joJIae",
        "Ujmp6XDhH3ik",
        "5O-U1l9aJKcG",
        "I3qOxQIcVP9V",
        "thiMOrniVP9b",
        "AwdmdzPtVP9c",
        "Ksnc87sZV6ML",
        "Sgtti1RdWFi9",
        "iA2puofsWWjP",
        "oW4oTqNwW8Ti",
        "6Zk0zu8HXI0Q",
        "0YZJTgryXYvD",
        "oDx3DRdRXoHb",
        "NWyJ5OZsYhI-",
        "SXRpB3dGYuSA",
        "p1e8gINTY9LH",
        "cRrtUBnAZYm3",
        "zXSXxgVtd1dZ",
        "Z5v6AuJme3Rf",
        "nD2_6W8efcTM"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}